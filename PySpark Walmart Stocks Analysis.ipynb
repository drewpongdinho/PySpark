{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82dace04-1c25-4b27-b7da-7af39efae8a0",
   "metadata": {},
   "source": [
    "## The following notebook contains examples of analysing A Walmart stock CSV obtained from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd2a9e5-001c-4e0a-8eca-2b4699a53cfd",
   "metadata": {},
   "source": [
    "#### Start a simple Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec113af-38fa-4df9-a43f-297bffe6fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# May take a little while on a local computer\n",
    "spark = SparkSession.builder.appName(\"exercises\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef92b55-9a1a-485a-81d5-951377fd1ab2",
   "metadata": {},
   "source": [
    "#### Load the Walmart Stock CSV File, have Spark infer the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35aaf087-5ab5-4099-927c-13107288f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"walmart_stock.csv\",header=True,\n",
    "                 inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb0bea6-6516-405c-8070-4a2f606c992d",
   "metadata": {},
   "source": [
    "#### What are the column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9409b5a-dc87-4c87-8bf0-21ce6c3f2854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e5afde-6053-4f1f-a09e-3609865ab98d",
   "metadata": {},
   "source": [
    "#### What does the Schema look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b560232-a4a8-4efa-bf7e-d3d145233f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eb9997-5ec8-42c9-9240-24f21bd5a385",
   "metadata": {},
   "source": [
    "#### Print out the first 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c5fc5e9a-e527-4e88-93c3-4c2478cd6750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Date=datetime.date(2012, 1, 3), Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996)\n",
      "\n",
      "\n",
      "Row(Date=datetime.date(2012, 1, 4), Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475)\n",
      "\n",
      "\n",
      "Row(Date=datetime.date(2012, 1, 5), Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539)\n",
      "\n",
      "\n",
      "Row(Date=datetime.date(2012, 1, 6), Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922)\n",
      "\n",
      "\n",
      "Row(Date=datetime.date(2012, 1, 9), Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df.select(['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']).show(5)\n",
    "for row in df.head(5):\n",
    "    print (row)\n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b47272-82c1-4b1e-b118-dfb3a144588b",
   "metadata": {},
   "source": [
    "#### Use describe() to learn about the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cb543e2-71f5-49fd-965f-57d19aa1496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
      "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
      "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735b0326-2674-4fda-ab96-469af32c8b31",
   "metadata": {},
   "source": [
    "## Bonus Question!\r\n",
    "#### There are too many decimal places for mean and stddev in the describe() dataframe. Format the numbers to just show up to two decimal places. Pay careful attention to the datatypes that .describe() returns, we didn't cover how to do this exact formatting, but we covered something very similar. [Check this link for a hint](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column.cast)\r\n",
    "\r\n",
    "If you get stuck on this, don't worry, just view the solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5e5ce2e-2edd-4869-af91-0c5ea021b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd3c9e-9074-4fbd-a715-e6c2e4a52cfd",
   "metadata": {},
   "source": [
    "#### Create a new dataframe with a column called HV Ratio that is the ratio of the High Price versus volume of stock traded for a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d386e250-3ead-4a38-8fd5-fbc916aef621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+--------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|            HV Ratio|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+--------------------+\n",
      "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|4.819714653321546E-6|\n",
      "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|6.290848613094555E-6|\n",
      "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|4.669412994783916E-6|\n",
      "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|7.367338463826307E-6|\n",
      "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|8.915604778943901E-6|\n",
      "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|8.644477436914568E-6|\n",
      "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|9.351828421515645E-6|\n",
      "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994| 8.29141562102703E-6|\n",
      "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|7.712212102001476E-6|\n",
      "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|7.071764823529412E-6|\n",
      "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|1.015495466386981E-5|\n",
      "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|6.576354146362592...|\n",
      "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996| 5.90145296180676E-6|\n",
      "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|8.547679455011844E-6|\n",
      "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|8.420709512685392E-6|\n",
      "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|1.041448341728929...|\n",
      "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|8.316075414862431E-6|\n",
      "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|9.721183814992126E-6|\n",
      "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|8.029436027707578E-6|\n",
      "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|6.307432259386365E-6|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.withColumn('HV Ratio',df['High']/df['Volume']).show()\n",
    "#df1 = df.withColumn('HV Ratio',df['High']/df['Volume']).select('HV Ratio').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa85bbf6-49fb-434b-b005-a3db3c5e10b5",
   "metadata": {},
   "source": [
    "#### What day had the Peak High in Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64a96448-224b-4447-a889-b94db3e61447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|      Date|             High|\n",
      "+----------+-----------------+\n",
      "|2015-01-13|        90.970001|\n",
      "|2015-01-08|90.66999799999999|\n",
      "|2015-01-09|        90.389999|\n",
      "|2015-01-12|        90.309998|\n",
      "|2015-01-23|        89.260002|\n",
      "|2015-01-26|        89.160004|\n",
      "|2015-01-07|            88.68|\n",
      "|2015-01-14|        88.519997|\n",
      "|2015-01-27|        88.459999|\n",
      "|2015-01-22|        88.400002|\n",
      "|2015-01-28|        88.230003|\n",
      "|2014-11-28|        88.089996|\n",
      "|2015-02-06|             88.0|\n",
      "|2015-01-15|        87.779999|\n",
      "|2015-01-29|        87.720001|\n",
      "|2015-01-20|        87.699997|\n",
      "|2015-01-16|        87.459999|\n",
      "|2014-12-31|        87.440002|\n",
      "|2015-02-10|        87.410004|\n",
      "|2015-01-30|        87.360001|\n",
      "+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df['High'].desc()).select(['Date','High']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477970cb-4a0b-4f45-88c6-df1a0544c8bc",
   "metadata": {},
   "source": [
    "#### What is the mean of the Close column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68b9ec12-df1a-42f6-b81c-5c22fbc81651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Close)|\n",
      "+-----------------+\n",
      "|72.38844998012726|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, max, min\n",
    "df.select(avg('Close')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b7e1b-e916-4c1e-835c-491ff3a0bb82",
   "metadata": {},
   "source": [
    "#### What is the max and min of the Volume column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73edc09d-eace-4875-aed0-d06043734356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|max(Volume)|\n",
      "+-----------+\n",
      "|   80898100|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max('Volume')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e41fd58-e6a5-4c17-97c3-367853fd19f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|min(Volume)|\n",
      "+-----------+\n",
      "|    2094900|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(min('Volume')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc2bc4-f269-42b6-b198-0ad50ac0210f",
   "metadata": {},
   "source": [
    "#### How many days was the Close lower than 60 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a44c0b9-5d8c-4a57-a2df-61ffffd266ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter('Close<60').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce26d5de-d075-4c5c-972a-fc587748d8e2",
   "metadata": {},
   "source": [
    "#### What percentage of the time was the High greater than 80 dollars ?\r\n",
    "#### In other words, (Number of Days High>80)/(Total Days in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5dc3fbfd-4cf7-4762-bf5c-3065aeceaa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = df.filter('High>80').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad22c1e0-7a06-478d-8a76-8728855d90a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT Date)|\n",
      "+--------------------+\n",
      "|                1258|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "data2 = df.select(countDistinct(\"Date\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b6527-52d3-4fff-a843-ac41923dfca9",
   "metadata": {},
   "source": [
    "#### What is the Pearson correlation between High and Volume?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e68a92-ba1c-4416-885a-1563bdbb7efa",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1a06c4d3-03d2-4054-b70e-a20f35763c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| corr(High, Volume)|\n",
      "+-------------------+\n",
      "|-0.3384326061737161|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(corr('High','Volume')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2be2b-fd4d-487c-b500-e6bff9eee390",
   "metadata": {},
   "source": [
    "#### What is the max High per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c549306b-3b9e-4552-b8f7-778ffd7ea79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+------------------+------------------+-----------+-----------------+\n",
      "|      Date|         max(Open)|max(High)|          max(Low)|        max(Close)|max(Volume)|   max(Adj Close)|\n",
      "+----------+------------------+---------+------------------+------------------+-----------+-----------------+\n",
      "|2012-04-17|61.110001000000004|61.950001|             61.09|         61.869999|   10676400|54.32359399999999|\n",
      "|2013-01-22|         69.050003|69.650002|         68.959999| 69.58000200000001|    5747900|62.18356899999999|\n",
      "|2013-03-26|             74.93|75.089996|             74.43|         74.769997|    6642400|67.25296999999999|\n",
      "|2013-05-21|         77.620003|    78.18|             77.25|         77.389999|    7484300|        70.027089|\n",
      "|2013-09-09|         72.849998|73.650002|         72.699997|         73.510002|    5523000|66.92014300000001|\n",
      "|2014-09-26|             76.25|    76.57|         75.860001|         76.489998|    3752900|        71.393879|\n",
      "|2014-11-12| 78.83000200000001|79.440002|         78.650002|         79.199997|    6791200|        73.923326|\n",
      "|2015-03-09|         82.589996|83.339996|         82.540001|         82.879997|    4671500|        77.790316|\n",
      "|2015-05-19|             78.18|78.360001|         76.230003|             76.43|   22458600|        72.622749|\n",
      "|2016-03-01|         66.650002|66.889999|              66.0|         66.459999|   10429500|        64.113152|\n",
      "|2012-07-17|         72.900002|73.099998|         72.309998|         73.099998|   12176300|        64.619388|\n",
      "|2013-09-19|              76.5|76.529999|         75.620003|         76.209999|    7109500|        69.378097|\n",
      "|2015-03-06|         82.809998|83.099998|         82.379997|         82.589996|    5731000|        77.518124|\n",
      "|2016-04-25|         68.550003|     69.5|         68.059998|         69.470001|    5896200|        67.512991|\n",
      "|2014-08-01|             73.32|73.879997|         73.220001|         73.540001|    8223900|        68.191182|\n",
      "|2015-04-09|         80.839996|81.389999| 80.58000200000001|         80.839996|    3923600|76.33133000000001|\n",
      "|2015-09-02|         64.589996|64.940002|         64.059998|         64.440002|    9514600|        61.648116|\n",
      "|2015-12-22|59.790001000000004|60.700001|59.610001000000004|60.540001000000004|    9266300|        58.402202|\n",
      "|2016-05-03|         66.860001|     67.5|             66.75|              67.0|    5906600|        65.112571|\n",
      "|2016-07-26|         73.709999|    74.07|         73.410004|         73.730003|    5248300|72.17760600000001|\n",
      "+----------+------------------+---------+------------------+------------------+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import format_number,dayofmonth,hour,dayofyear,month,year,weekofyear,date_format\n",
    "#df.select(dayofmonth(df['Date'])).show()\n",
    "df.groupBy('Date').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "aa92dc35-8e80-45cd-940a-b2c476410566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Year|max(High)|\n",
      "+----+---------+\n",
      "|2012|77.599998|\n",
      "|2013|81.370003|\n",
      "|2014|88.089996|\n",
      "|2015|90.970001|\n",
      "|2016|75.190002|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(year('Date').alias('Year')).max().select('Year','max(High)').orderBy('Year').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb6ce2-908b-4f40-8dcf-9a7bea2d033f",
   "metadata": {},
   "source": [
    "#### What is the average Close for each Calendar Month?\n",
    "#### In other words, across all the years, what is the average Close price for Jan,Feb, Mar, etc... Your result will have a value for each of these months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8c2ee42e-eb07-4682-8a9d-228dbf329b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|Month|       avg(Close)|\n",
      "+-----+-----------------+\n",
      "|    1|71.44801958415842|\n",
      "|    2|  71.306804443299|\n",
      "|    3|71.77794377570092|\n",
      "|    4|72.97361900952382|\n",
      "|    5|72.30971688679247|\n",
      "|    6| 72.4953774245283|\n",
      "|    7|74.43971943925233|\n",
      "|    8|73.02981855454546|\n",
      "|    9|72.18411785294116|\n",
      "|   10|71.57854545454543|\n",
      "|   11| 72.1110893069307|\n",
      "|   12|72.84792478301885|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(month('Date').alias('Month')).avg().select('Month','avg(Close)').orderBy('Month').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f1895-bae4-4579-af7c-ea8e965c9f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
